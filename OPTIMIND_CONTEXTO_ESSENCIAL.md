# OptiMind - Contexto Essencial para Desenvolvimento

## üéØ Prop√≥sito

Este documento cont√©m **contexto essencial** que n√£o est√° nos outros MDs mas √© crucial para continuar o desenvolvimento do OptiMind. Se voc√™ est√° retomando o projeto, leia este documento **antes** dos outros.

---

## üèóÔ∏è Decis√µes Arquiteturais Fundamentais

### 1. Por que PraisonAI?
- **Escolhido sobre LangChain**: PraisonAI tem integra√ß√£o nativa com Streamlit e suporte a multi-agentes mais robusto
- **Vantagens**: Sandbox autom√°tico, ferramentas integradas, menos boilerplate
- **Alternativa considerada**: AutoGen (mais complexo) ou LangGraph (mais verboso)

### 2. Por que 6 Agentes Espec√≠ficos?
- **Entendimento**: Separa√ß√£o clara entre input humano e processamento
- **Pesquisador**: Necess√°rio para problemas complexos que precisam de refinamento
- **Matem√°tico**: Gera tanto LaTeX quanto JSON estruturado
- **Formulador**: Especializado em Pyomo, escolhe solver automaticamente
- **Executor**: Sandbox separado por seguran√ßa
- **Interpretador**: Traduz resultados t√©cnicos para insights de neg√≥cio
- **Auditor**: Meta-agente que valida todo o pipeline

### 3. Por que JSON Schemas R√≠gidos?
- **Problema**: LLMs √†s vezes geram JSON inv√°lido ou inconsistente
- **Solu√ß√£o**: Valida√ß√£o rigorosa em cada etapa
- **Benef√≠cio**: Detecta erros cedo, permite retry autom√°tico

---

## üîß Padr√µes de Implementa√ß√£o

### 1. Estrutura de Agentes
```python
# Padr√£o para todos os agentes
class BaseAgent:
    def __init__(self, name, system_prompt):
        self.name = name
        self.system_prompt = system_prompt
        self.llm = OpenAI(model="gpt-4o-mini")  # Usar modelo menor para custo
    
    def process(self, input_data):
        # 1. Validar input
        # 2. Chamar LLM
        # 3. Validar output
        # 4. Retornar resultado
        pass

class EntendimentoAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="Entendimento",
            system_prompt=load_prompt("entendimento.txt")
        )
```

### 2. Padr√£o de Comunica√ß√£o
```python
# Todas as mensagens seguem este formato
message = {
    "message_id": generate_uuid(),
    "sender": agent_name,
    "recipient": next_agent_name,
    "type": message_type,
    "timestamp": datetime.now().isoformat(),
    "content": validated_json_data
}
```

### 3. Padr√£o de Valida√ß√£o
```python
# Para cada etapa
def validate_stage_output(output, schema):
    try:
        jsonschema.validate(instance=output, schema=schema)
        return True, None
    except jsonschema.ValidationError as e:
        return False, str(e)
```

---

## üé® Decis√µes de UX/UI

### 1. Fluxo de Usu√°rio
- **Por que confirma√ß√£o obrigat√≥ria?**: Evita processamento desnecess√°rio e custos
- **Por que timeline visual?**: Transpar√™ncia do processo, confian√ßa do usu√°rio
- **Por que JSON colaps√°vel?**: T√©cnicos podem ver detalhes, leigos n√£o se confundem

### 2. Tratamento de Erros
- **Nunca mostrar stack trace**: Sempre mensagens amig√°veis
- **Sugest√µes espec√≠ficas**: "Tente adicionar 'maximizar' ou 'minimizar' ao seu problema"
- **Retry autom√°tico**: Se poss√≠vel, sem interven√ß√£o do usu√°rio

### 3. Loading States
- **Spinners espec√≠ficos**: Cada agente tem seu pr√≥prio indicador
- **Tempo estimado**: Mostrar progresso baseado em experi√™ncia
- **Cancelamento**: Permitir parar em qualquer momento

---

## üîí Decis√µes de Seguran√ßa

### 1. Sandbox de Execu√ß√£o
```python
# Pyomo roda em container isolado
executor_config = {
    "timeout": 300,  # 5 minutos
    "memory_limit": "1GB",
    "allowed_imports": ["pyomo", "numpy", "pandas"],
    "blocked_imports": ["os", "subprocess", "sys", "requests"]
}
```

### 2. Rate Limiting
- **Por usu√°rio**: 50 chamadas por dia
- **Por sess√£o**: 10 chamadas por hora
- **Por IP**: 100 chamadas por dia (backup)

### 3. Prote√ß√£o de Dados
- **Nenhum dado persistido**: Tudo em session_state
- **Logs anonimizados**: Sem dados pessoais
- **Chaves nunca expostas**: Apenas no backend

---

## üí∞ Decis√µes de Custo

### 1. Modelos LLM
- **GPT-4o-mini**: Para agentes simples (Entendimento, Pesquisador)
- **GPT-4o**: Para agentes complexos (Matem√°tico, Formulador)
- **Custo estimado**: $0.01-0.10 por job completo

### 2. Otimiza√ß√µes
- **Cache de prompts**: Evitar regenera√ß√£o
- **Batch processing**: Se poss√≠vel, processar m√∫ltiplos problemas
- **Modelos menores**: Para valida√ß√µes simples

### 3. Monitoramento de Custos
```python
# Rastrear custos por usu√°rio
def track_cost(user_id, tokens_used, model):
    cost = calculate_cost(tokens_used, model)
    update_user_usage(user_id, cost)
    if cost > daily_limit:
        block_user(user_id)
```

---

## üß™ Decis√µes de Testes

### 1. Casos de Teste Essenciais
```python
# Problemas que DEVEM funcionar
test_cases = [
    "Maximize 3x + 4y subject to x + y <= 10",  # LP simples
    "Minimize cost where x + y >= 5, x,y integer",  # MIP
    "Maximize profit with x <= 100, y <= 50",  # LP com bounds
    "Invalid input: Hello world",  # Deve ser rejeitado
    "Maximize x + y with x + y <= 5, x >= 10",  # Invi√°vel
]
```

### 2. Valida√ß√£o de Schemas
- **Teste cada schema**: Com dados v√°lidos e inv√°lidos
- **Teste edge cases**: JSON vazio, campos faltando, tipos errados
- **Teste performance**: Schemas n√£o devem demorar >1s

### 3. Testes de Integra√ß√£o
- **Pipeline completo**: Do input ao resultado
- **Erro handling**: Cada ponto de falha
- **Performance**: Tempo total <30s

---

## üöÄ Decis√µes de Deploy

### 1. Streamlit Community Cloud
- **Limita√ß√µes conhecidas**: 1GB RAM, 1 vCPU, 60s timeout
- **Adapta√ß√µes necess√°rias**: Usar modelos menores, otimizar mem√≥ria
- **Alternativas**: Render, Heroku se necess√°rio

### 2. Secrets Management
```toml
# .streamlit/secrets.toml (n√£o no git)
[OPENAI]
api_key = "sk-..."

[USERS]
admin_password_hash = "$2b$12$..."
user1_password_hash = "$2b$12$..."

[LIMITS]
max_calls_per_day = 50
max_calls_per_hour = 10
```

### 3. Monitoramento
- **Logs estruturados**: Para debugging
- **M√©tricas b√°sicas**: Uso, erros, performance
- **Alertas**: Se custo > limite ou erros > threshold

---

## üîÑ Padr√µes de Retry e Fallback

### 1. Estrat√©gia de Retry
```python
# Para cada agente
def execute_with_retry(agent, input_data, max_retries=2):
    for attempt in range(max_retries):
        try:
            result = agent.process(input_data)
            if validate_result(result):
                return result
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(1)  # Backoff simples
```

### 2. Fallback de Solvers
```python
# Se CBC falha, tentar GLPK
solver_fallback = {
    "cbc": ["glpk", "highs"],
    "glpk": ["highs"],
    "highs": ["glpk"]
}
```

### 3. Fallback de Modelos
```python
# Se GPT-4o falha, usar GPT-4o-mini
model_fallback = {
    "gpt-4o": ["gpt-4o-mini"],
    "gpt-4o-mini": ["gpt-3.5-turbo"]
}
```

---

## üìä Decis√µes de Performance

### 1. Otimiza√ß√µes Cr√≠ticas
- **Cache de prompts**: Evitar regenera√ß√£o
- **Lazy loading**: Carregar agentes sob demanda
- **Connection pooling**: Para chamadas OpenAI
- **Compress√£o**: Para dados grandes

### 2. Limites de Recursos
- **Mem√≥ria**: <800MB para funcionar no Streamlit Cloud
- **Tempo**: <30s para job completo
- **API calls**: <10 por job
- **Tokens**: <2000 por agente

### 3. Monitoramento de Performance
```python
# M√©tricas essenciais
performance_metrics = {
    "total_time": float,
    "agent_times": dict,
    "api_calls": int,
    "tokens_used": int,
    "memory_peak": float
}
```

---

## üéØ Decis√µes de Neg√≥cio

### 1. P√∫blico-Alvo
- **Prim√°rio**: Consultores de otimiza√ß√£o n√£o-t√©cnicos
- **Secund√°rio**: Estudantes e pesquisadores
- **N√£o focado**: Desenvolvedores experientes

### 2. Limita√ß√µes Aceit√°veis
- **Problemas simples**: LP, MIP b√°sicos
- **N√£o suportado**: Problemas estoc√°sticos complexos, NLP avan√ßado
- **Escalabilidade**: At√© 100 usu√°rios simult√¢neos

### 3. Roadmap de Features
- **Fase 1**: Problemas lineares e inteiros
- **Fase 2**: Problemas n√£o-lineares simples
- **Fase 3**: Problemas estoc√°sticos
- **Fase 4**: API para integra√ß√£o

---

## üîß Configura√ß√µes T√©cnicas Espec√≠ficas

### 1. Vers√µes de Depend√™ncias
```txt
# requirements.txt - vers√µes espec√≠ficas
streamlit==1.28.0
praisonaiagents==0.1.0
pyomo==6.8.0
openai==1.3.0
jsonschema==4.19.0
streamlit-authenticator==0.2.0
```

### 2. Configura√ß√£o Streamlit
```toml
# .streamlit/config.toml
[theme]
primaryColor="#020e66"
backgroundColor="#f8fafc"
secondaryBackgroundColor="#c8f0ff"
textColor="#1f2937" 

[server]
maxUploadSize = 200
enableXsrfProtection = true
enableCORS = false

[browser]
gatherUsageStats = false
```

### 3. Estrutura de Pastas
```
optimind/
‚îú‚îÄ‚îÄ app.py                    # Entry point
‚îú‚îÄ‚îÄ agents/                   # Todos os agentes
‚îú‚îÄ‚îÄ schemas/                  # JSON schemas
‚îú‚îÄ‚îÄ prompts/                  # Prompt templates
‚îú‚îÄ‚îÄ utils/                    # Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ tests/                    # Testes
‚îú‚îÄ‚îÄ examples/                 # Exemplos de problemas
‚îî‚îÄ‚îÄ .streamlit/              # Configura√ß√µes
```

---

## üö® Problemas Conhecidos e Solu√ß√µes

### 1. LLM Hallucination
- **Problema**: Agentes √†s vezes inventam dados
- **Solu√ß√£o**: Valida√ß√£o rigorosa de schemas
- **Fallback**: Pedir esclarecimentos ao usu√°rio

### 2. Solver Infeasibility
- **Problema**: Problemas sem solu√ß√£o vi√°vel
- **Solu√ß√£o**: Detectar e explicar claramente
- **Fallback**: Sugerir relaxamento de restri√ß√µes

### 3. Timeout Issues
- **Problema**: Problemas complexos demoram muito
- **Solu√ß√£o**: Timeout de 5 minutos
- **Fallback**: Sugerir simplifica√ß√£o do problema

### 4. Memory Constraints
- **Problema**: Streamlit Cloud tem 1GB RAM
- **Solu√ß√£o**: Otimizar uso de mem√≥ria
- **Fallback**: Limitar tamanho dos problemas

---

## üìö Recursos e Refer√™ncias Essenciais

### 1. Documenta√ß√£o Principal
- [PraisonAI Docs](https://docs.praison.ai/)
- [Streamlit Docs](https://docs.streamlit.io/)
- [Pyomo Docs](https://pyomo.readthedocs.io/)
- [OpenAI API Docs](https://platform.openai.com/docs)

### 2. Exemplos √öteis
- [Streamlit Multi-Agent Example](https://github.com/leporejoseph/PraisonAi-Streamlit)
- [Pyomo Optimization Examples](https://pyomo.readthedocs.io/en/stable/working_models.html)

### 3. Ferramentas de Debug
- [JSON Schema Validator](https://www.jsonschemavalidator.net/)
- [OpenAI Token Counter](https://platform.openai.com/tokenizer)

---

## üéØ Checklist de Continuidade

### Antes de Retomar Desenvolvimento
- [ ] Ler este documento completamente
- [ ] Verificar estado atual do projeto
- [ ] Validar configura√ß√µes de ambiente
- [ ] Testar conex√µes (OpenAI, Streamlit)
- [ ] Revisar √∫ltimo bloco implementado

### Durante Desenvolvimento
- [ ] Seguir padr√µes estabelecidos
- [ ] Manter compatibilidade com decis√µes arquiteturais
- [ ] Documentar mudan√ßas significativas
- [ ] Testar continuamente
- [ ] Monitorar custos e performance

### Ap√≥s Implementa√ß√£o
- [ ] Validar crit√©rios de sucesso
- [ ] Testar em produ√ß√£o
- [ ] Atualizar documenta√ß√£o
- [ ] Planejar pr√≥ximo bloco

---

**Vers√£o**: 1.0  
**Data**: Janeiro 2024  
**Status**: Contexto essencial para desenvolvimento 